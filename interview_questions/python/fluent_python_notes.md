## Command design pattern

Can be simplified by the use of functions passed as arguments

The goal of command is to decouple an object that invokes an operation from the provider object that implements it.
The idea is to put a Command object between the two implementing an interface with a single method, execute, which calls
some method in the Receiver to perform the desired operation. That way the Invoker does not need to know the interface
of the Receiver, and the different receivers can be adapted through Command subclasses. The Invoker is configured with
with a concrete command and calls its execute method to operate it.
"Commands are object oriented replacement for callbacks." - Gamma

```python
class MacroCommand:
    """A command that executes a list of commands"""

    def __init__(self, commands):
        self.commands = list(commands)

    def __call__(self):
        for command in commands:
            command()
```

A callable instance like MacroCommand can keep whatever state is necessarry and provide extra methods in addition to
**call**

Summary:
Replacing with callables the instances of the participating class that implemented a single method interface. After all
all Python callable implements a single method interface, and that method is **call** .

## Function decorators and closures

Aside from their application in decorators, closures are also essential for effective asynchronous programming with
callbacks, and for coding in a functional style whenever it makes sense.

### Decorators

A decorator is a callable that takes another function as an argument. The decorator may perform some processing with the
decorated function returns it or replaces it with another function or callable object.

```python
@decorate
def target():
    print("running target!")


def target():
    print("running target!")

target = decorate(target)

def deco(func):
    def inner():
        print("running inner!")
    return inner


@deco
def target():
    print("running target!")

target()

>>> running inner!
>>> target
<function deco.<locals>.inner at 0x10063b598>
```

deco returns its inner function object.
target is decorated by deco .
Invoking the decorated target actually runs inner .
Inspection reveals that target is a now a reference to inner .

Python executes decorators right after the decorated function is defined. That is usually at import time (when the
module is loaded by Python).

### Variable scope rules

Example 7-4. Function reading a local and a global variable

```python
>>> def f1(a):
...
print(a)
...
print(b)
...
>>> f1(3)
3
Traceback (most recent
File "<stdin>", line
File "<stdin>", line
NameError: global name
call last):
1, in <module>
3, in f1
'b' is not defined
# The error we got is not surprising. Continuing from Example 7-4, if we assign a value
# to a global b and then call f1 , it works:
>>> b = 6
>>> f1(3)
3
6
```

Another example:

```python
>>> b = 6
>>> def f2(a):
...
print(a)
...
print(b)
...
b = 9
...
>>> f2(3)
3
Traceback (most recent call last):
File "<stdin>", line 1, in <module>
File "<stdin>", line 3, in f2
UnboundLocalError: local variable 'b' referenced before assignment
```

But the fact is, when Python compiles the body of the function, it decides that b is a
local variable because it is assigned within the function. The generated bytecode
reflects this decision and will try to fetch b from the local environment. Later, when
the call f2(3) is made, the body of f2 fetches and prints the value of the local variable
a , but when trying to fetch the value of local variable b it discovers that b is unbound.

```python

b = 6
def f3(a):
    global b
    print(a)
    print(b)
    b = 9
f3(3)
3
6
b
9
```

### Closures

A closure is a function with an extended scope that encompasses nonglobal variables referenced in the body of the function
but not defined there. It does not matter whether the function is anonymous or not what matters is that it can access
nonglobal variables that are defined outside its body.
Example:
Consider an avg function to compute the mean of an ever-increasing series of values;
for example, the average closing price of a commodity over its entire history. Every
day a new price is added, and the average is computed taking into account all prices
so far.
Starting with a clean slate, this is how avg could be used:

```python
>>> avg(10)
10.0
>>> avg(11)
10.5
>>> avg(12)
11.0
```

Where does avg come from, and where does it keep the history of previous values?

```python
class Averager:
    def __init__(self):
        self.series = []

    def __call__(self, new_value):
        self.series.append(new_value)
        total = sum(self.series)
        return total / len(self.series)

>>> avg = Averager()
>>> avg(10)
10.0
>>> avg(11)
10.5
>>> avg(12)
11.0
```

A higher-order function to calculate a running average:

```python
def make_averager():
    series = []
    def averager(new_value):
        series.append(new_value)
        total = sum(series)
        return total / len(series)
    return averager

>>> avg = make_averager()
>>> avg(10)
10.0
>>> avg(11)
10.5
>>> avg(12)
11.0
```

Within averager , series is a free variable. This is a technical term meaning a vari‐
able that is not bound in the local scope.
Our previous implementation of make_averager was not efficient. In Example 7-9,
we stored all the values in the historical series and computed their sum every time
averager was called. A better implementation would just store the total and the
number of items so far, and compute the mean from these two numbers.

```python
def make_averager():
    count = 0
    total = 0
    def averager(new_value):
        count += 1
        total += new_value
        return total / count
    return averager

>>> avg = make_averager()
>>> avg(10)
Traceback (most recent call last):
...
UnboundLocalError: local variable 'count' referenced before assignment
```

The problem is that the statement count += 1 actually means the same as count =
count + 1 , when count is a number or any immutable type. So we are actually
assigning to count in the body of averager , and that makes it a local variable. The
same problem affects the total variable.

Fix:

```python
def make_averager():
    count = 0
    total = 0
    def averager(new_value):
        nonlocal count, total
        count += 1
        total += new_value
        return total / count
    return averager
```

### Memoization with functools.lru_cache

A very practical decorator is functools.lru_cache . It implements memoization: an
optimization technique that works by saving the results of previous invocations of an
expensive function, avoiding repeat computations on previously used arguments.
The letters LRU stand for Least Recently Used, meaning that the growth of the cache
is limited by discarding the entries that have not been read for a while.

A good demonstration is to apply lru_cache to the painfully slow recursive function
to generate the nth number in the Fibonacci sequence

### Parameterized Decorators

When parsing a decorator in source code, Python takes the decorated function and
passes it as the first argument to the decorator function. So how do you make a deco‐
rator accept other arguments? The answer is: make a decorator factory that takes
those arguments and returns a decorator, which is then applied to the function to be
decorated

In order to make it easy to enable or disable the function registration performed by
register , we’ll make it accept an optional active parameter which, if False , skips
registering the decorated function. Example 7-23 shows how. Conceptually, the new
register function is not a decorator but a decorator factory. When called, it returns
the actual decorator that will be applied to the target function.

```python
registry = set()
def register(active=True):
    def decorate(func):
        print('running register(active=%s)->decorate(%s)' % (active, func))
        if active:
            registry.add(func)
        else:
            registry.discard(func)
        return func
    return decorate

@register(active=False)
def f1():
    print('running f1()')
@register()
def f2():
    print('running f2()')
def f3():
    print('running f3()')
```

- registry is now a set , so adding and removing functions is faster.
- register takes an optional keyword argument.
- The decorate inner function is the actual decorator; note how it takes a function as argument.
- Register func only if the active argument (retrieved from the closure) is True .
- If not active and func in registry , remove it.
- Because decorate is a decorator, it must return a function.
- register is our decorator factory, so it returns decorate .
- The @register factory must be invoked as a function, with the desired parameters.
- If no parameters are passed, register must still be called as a function— @register() —i.e., to return the
  actual decorator, decorate .

The main point is that register() returns decorate , which is then applied to the
decorated function

Note how only the f2 function appears in the registry ; f1 does not appear because
active=False was passed to the register decorator factory, so the decorate that
was applied to f1 did not add it to the registry .

## Identity, equality and aliases

```python
>>> charles = {'name': 'Charles L. Dodgson', 'born': 1832}
>>> lewis = charles
>>> lewis is charles
True
>>> id(charles), id(lewis)
(4300473992, 4300473992)
>>> lewis['balance'] = 950
>>> charles
{'name': 'Charles L. Dodgson', 'balance': 950, 'born': 1832}
```

lewis is an alias for charles .
The is operator and the id function confirm it.
Adding an item to lewis is the same as adding an item to charles

```python
>>> alex = {'name': 'Charles L. Dodgson', 'born': 1832, 'balance': 950}
>>> alex == charles
True
>>> alex is not charles
True
```

alex refers to an object that is a replica of the object assigned to charles .
The objects compare equal, because of the **eq** implementation in the dict
class.

But they are distinct objects. This is the Pythonic way of writing the negative
identity comparison: a is not b .

Above examples are examples of aliasing. In that code, lewis and charles are aliases:
two variables bound to the same object. On the other hand, alex is not an alias for
charles : these variables are bound to distinct objects. The objects bound to alex and
charles have the same value—that’s what == compares—but they have different
identities.

Every object has an identity, a type and a value. An object’s identity never changes
once it has been created; you may think of it as the object’s address in memory. The is
operator compares the identity of two objects; the id() function returns an integer
representing its identity.

### Choosing Between == and is

The == operator compares the values of objects (the data they hold), while is com‐
pares their identities.
We often care about values and not identities, so == appears more frequently than is
in Python code.
However, if you are comparing a variable to a singleton, then it makes sense to use
is . By far, the most common case is checking whether a variable is bound to None .
This is the recommended way to do it:
x is None
And the proper way to write its negation is:
x is not None

The is operator is faster than == , because it cannot be overloaded, so Python does
not have to find and invoke special methods to evaluate it, and computing is as sim‐
ple as comparing two integer IDs. In contrast, a == b is syntactic sugar for
a.**eq**(b) . The **eq** method inherited from object compares object IDs, so it
produces the same result as is . But most built-in types override **eq** with more
meaningful implementations that actually take into account the values of the object
attributes. Equality may involve a lot of processing—for example, when comparing
large collections or deeply nested structures.
To wrap up this discussion of identity versus equality, we’ll see that the famously
immutable tuple is not as rigid as you may expect.

### Immutability

Using the constructor or [:] produces a shallow copy (i.e., the outermost
container is duplicated, but the copy is filled with references to the same items held
by the original container). This saves memory and causes no problems if all the items
are immutable. But if there are mutable items, this may lead to unpleasant surprises.

Note that making deep copies is not a simple matter in the general case. Objects may
have cyclic references that would cause a naïve algorithm to enter an infinite loop.
The deepcopy function remembers the objects already copied to handle cyclic refer‐
ences gracefully.

### Weak References

The presence of references is what keeps an object alive in memory. When the refer‐
ence count of an object reaches zero, the garbage collector disposes of it. But some‐
times it is useful to have a reference to an object that does not keep it around longer
than necessary. A common use case is a cache.
Weak references are useful in caching applications because you don’t want the
cached objects to be kept alive just because they are referenced by the cache.

The weakref module documentation makes the point that the weakref.ref class is
actually a low-level interface intended for advanced uses, and that most programs are
better served by the use of the weakref collections and finalize . In other words,
consider using WeakKeyDictionary , WeakValueDictionary , WeakSet , and finalize
(which use weak references internally) instead of creating and handling your own
weakref.ref instances by hand.

### Object Representations

Every object-oriented language has at least one standard way of getting a string repre‐
sentation from any object. Python has two:
repr()
Return a string representing the object as the developer wants to see it.
str()
Return a string representing the object as the user wants to see it.

### classmethod vs staticmethod

Let’s start with classmethod . Example 9-3 shows its use: to define a method that
operates on the class and not on instances. classmethod changes the way the method
is called, so it receives the class itself as the first argument, instead of an instance. Its
most common use is for alternative constructors, like frombytes in Example 9-3.
Note how the last line of frombytes actually uses the cls argument by invoking it to
build a new instance: cls(\*memv) . By convention, the first parameter of a class
method should be named cls (but Python doesn’t care how it’s named).

In contrast, the staticmethod decorator changes a method so that it receives no spe‐
cial first argument. In essence, a static method is just like a plain function that hap‐
pens to live in a class body, instead of being defined at the module level.

```python
@classmethod
def frombytes(cls, octets):
    typecode = chr(octets[0])
    memv = memoryview(octets[1:]).cast(typecode)
    return cls(*memv)
```

```python
>>> class Demo:
        @classmethod
        def klassmeth(*args):
            return args
        @staticmethod
        def statmeth(*args):
            return args
>>> Demo.klassmeth()
(<class '__main__.Demo'>,)
>>> Demo.klassmeth('spam')
(<class '__main__.Demo'>, 'spam')
>>> Demo.statmeth()
()
>>> Demo.st
```

klassmeth just returns all positional arguments.
statmeth does the same.
No matter how you invoke it, Demo.klassmeth receives the Demo class as the first
argument.
Demo.statmeth behaves just like a plain old function.

The classmethod decorator is clearly useful, but I’ve never seen a
compelling use case for staticmethod . If you want to define a
function that does not interact with the class, just define it in the
module. Maybe the function is closely related even if it never
touches the class, so you want to them nearby in the code. Even so,
defining the function right before or after the class in the same
module is close enough for all practical purposes. 5

### Saving memory with **slots**

By default, Python stores instance attributes in a per-instance dict named **dict** .
As we saw in “Practical Consequences of How dict Works” on page 95, dictionaries
have a significant memory overhead because of the underlying hash table used to
provide fast access. If you are dealing with millions of instances with few attributes,
the **slots** class attribute can save a lot of memory, by letting the interpreter store
the instance attributes in a tuple instead of a dict .

A **slots** attribute inherited from a superclass has no effect.
Python only takes into account **slots** attributes defined in
each class individually.

```python
class Vector2d:
    __slots__ = ('__x', '__y')
    typecode = 'd'
    # methods follow (omitted in book listing)
```

By defining **slots** in the class, you are telling the interpreter: “These are all the
instance attributes in this class.” Python then stores them in a tuple-like structure in
each instance, avoiding the memory overhead of the per-instance **dict** . This can
make a huge difference in memory usage if you have millions of instances active at
the same time.

##### TIP:

If you are handling millions of objects with numeric data, you
should really be using NumPy arrays (see “NumPy and SciPy” on
page 55), which are not only memory-efficient but have highly
optimized functions for numeric processing, many of which oper‐
ate on the entire array at once.

### Multiple inheritance and method resolution order

```python
class A:
    def ping(self):
        print('ping:', self)

class B(A):
    def pong(self):
        print('pong:', self)

class C(A):
    def pong(self):
        print('PONG:', self)

class D(B, C):
    def ping(self):
        super().ping()
        print('post-ping:', self)

    def pingpong(self):
        self.ping()
        super().ping()
        self.pong()
        super().pong()
        C.pong(self)

>>> d = D()
>>> d.pong()
pong: <diamond.D object at 0x10066c278>
>>> C.pong(d)
PONG: <diamond.D object at 0x10066c278>
```

Simply calling d.pong() causes the B version to run.
You can always call a method on a superclass directly, passing the instance as an
explicit argument.

The ambiguity of a call like d.pong() is resolved because Python follows a specific
order when traversing the inheritance graph. That order is called MRO: Method Res‐
olution Order. Classes have an attribute called **mro** holding a tuple of references
to the superclasses in MRO order, from the current class all the way to the object
class. For the D class, this is the **mro**

```python
>>> D.__mro__
(<class 'diamond.D'>, <class 'diamond.B'>, <class 'diamond.C'>,
<class 'diamond.A'>, <class 'object'>)
```

### Coping with multiple inheritance

Use Mixins for Code Reuse
If a class is designed to provide method implementations for reuse by multiple unre‐
lated subclasses, without implying an “is-a” relationship, it should be an explicit
mixin class. Conceptually, a mixin does not define a new type; it merely bundles
methods for reuse. A mixin should never be instantiated, and concrete classes should
not inherit only from a mixin. Each mixin should provide a single specific behavior,
implementing few and very closely related methods.

Make Mixins Explicit by Naming
There is no formal way in Python to state that a class is a mixin, so it is highly recom‐
mended that they are named with a ...Mixin suffix. Tkinter does not follow this advice,
but if it did, XView would be XViewMixin , Pack would be PackMixin , and so on with
all the classes where I put the «mixin» tag in Figure 12-3.

Don’t Subclass from More Than One Concrete Class
Concrete classes should have zero or at most one concrete superclass. 6 In other
words, all but one of the superclasses of a concrete class should be ABCs or mixins.
For example, in the following code, if Alpha is a concrete class, then Beta and Gamma
must be ABCs or mixins:

```python
class MyConcreteClass(Alpha, Beta, Gamma):
    """This is a concrete class: it can be instantiated."""
    # ... more code ...
```

### Operator Overloading 101

Operator overloading has a bad name in some circles. It is a language feature that can
be (and has been) abused, resulting in programmer confusion, bugs, and unexpected
performance bottlenecks. But if well used, it leads to pleasurable APIs and readable
code. Python strikes a good balance between flexibility, usability, and safety by
imposing some limitations:
• We cannot overload operators for the built-in types.
• We cannot create new operators, only overload existing ones.
• A few operators can’t be overloaded: is , and , or , not (but the bitwise & , | , ~ , can).

Dunder or magic methods in Python are the methods having two prefix and suffix underscores in the method name. Dunder here means “Double Under (Underscores)”. These are commonly used for operator overloading. Few examples for magic methods are: **init**, **add**, **len**, **repr** etc.

### Iterators

Whenever the interpreter needs to iterate over an object x , it automatically calls
iter(x) .
The iter built-in function:

1. Checks whether the object implements **iter** , and calls that to obtain an iter‐
   ator.
2. If **iter** is not implemented, but **getitem** is implemented, Python cre‐
   ates an iterator that attempts to fetch items in order, starting from index 0 (zero).
3. If that fails, Python raises TypeError , usually saying “C object is not iterable,”
   where C is the class of the target object.

That is why any Python sequence is iterable: they all implement **getitem** . In fact,
the standard sequences also implement **iter** , and yours should too, because the
special handling of **getitem** exists for backward compatibility reasons and may
be gone in the future (although it is not deprecated as I write this).

Iterable
Any object from which the iter built-in function can obtain an iterator. Objects
implementing an **iter** method returning an iterator are iterable. Sequences
are always iterable; as are objects implementing a **getitem** method that takes
0-based indexes.

It’s important to be clear about the relationship between iterables and iterators:
Python obtains iterators from iterables.

Iterable is an object, which one can iterate over. It generates an Iterator when passed to iter() method. Iterator is an object, which is used to iterate over an iterable object using **next**() method. Iterators have **next**() method, which returns the next item of the object.

### Context managers

The with statement sets up a temporary context and reliably tears it down, under the
control of a context manager object. This prevents errors and reduces boilerplate
code, making APIs at the same time safer and easier to use. Python programmers are
finding lots of uses for with blocks beyond automatic file closing.

Using else with for, while, try:
Here are the rules:
for
The else block will run only if and when the for loop runs to completion (i.e.,
not if the for is aborted with a break ).
while
The else block will run only if and when the while loop exits because the condi‐
tion became falsy (i.e., not when the while is aborted with a break ).
try
The else block will only run if no exception is raised in the try block. The offi‐
cial docs also state: “Exceptions in the else clause are not handled by the preced‐
ing except clauses.”

### Meta Programming

Class metaprogramming is the art of creating or customizing classes at runtime.
Classes are first-class objects in Python, so a function can be used to create a new
class at any time, without using the class keyword. Class decorators are also func‐
tions, but capable of inspecting, changing, and even replacing the decorated class
with another class. Finally, metaclasses are the most advanced tool for class meta‐
programming: they let you create whole new categories of classes with special traits,
such as the abstract base classes we’ve already seen.

Consider the Python object model: classes are objects, therefore each class must be an
instance of some other class. By default, Python classes are instances of type .

A metaclass is the class of a class. A class defines how an instance of the class (i.e. an object) behaves while a metaclass defines how a class behaves. A class is an instance of a metaclass.

While in Python you can use arbitrary callables for metaclasses (like Jerub shows), the better approach is to make it an actual class itself. type is the usual metaclass in Python. type is itself a class, and it is its own type. You won't be able to recreate something like type purely in Python, but Python cheats a little. To create your own metaclass in Python you really just want to subclass type.

A metaclass is most commonly used as a class-factory. When you create an object by calling the class, Python creates a new class (when it executes the 'class' statement) by calling the metaclass. Combined with the normal **init** and **new** methods, metaclasses therefore allow you to do 'extra things' when creating a class, like registering the new class with some registry or replace the class with something else entirely.

When the class statement is executed, Python first executes the body of the class statement as a normal block of code. The resulting namespace (a dict) holds the attributes of the class-to-be. The metaclass is determined by looking at the baseclasses of the class-to-be (metaclasses are inherited), at the **metaclass** attribute of the class-to-be (if any) or the **metaclass** global variable. The metaclass is then called with the name, bases and attributes of the class to instantiate it.

However, metaclasses actually define the type of a class, not just a factory for it, so you can do much more with them. You can, for instance, define normal methods on the metaclass. These metaclass-methods are like classmethods in that they can be called on the class without an instance, but they are also not like classmethods in that they cannot be called on an instance of the class. type.**subclasses**() is an example of a method on the type metaclass. You can also define the normal 'magic' methods, like **add**, **iter** and **getattr**, to implement or change how the class behaves.

Here's an aggregated example of the bits and pieces:

```python
def make_hook(f):
    """Decorator to turn 'foo' method into '__foo__'"""
    f.is_hook = 1
    return f

class MyType(type):
    def __new__(mcls, name, bases, attrs):

        if name.startswith('None'):
            return None

        # Go over attributes and see if they should be renamed.
        newattrs = {}
        for attrname, attrvalue in attrs.iteritems():
            if getattr(attrvalue, 'is_hook', 0):
                newattrs['__%s__' % attrname] = attrvalue
            else:
                newattrs[attrname] = attrvalue

        return super(MyType, mcls).__new__(mcls, name, bases, newattrs)

    def __init__(self, name, bases, attrs):
        super(MyType, self).__init__(name, bases, attrs)

        # classregistry.register(self, self.interfaces)
        print "Would register class %s now." % self

    def __add__(self, other):
        class AutoClass(self, other):
            pass
        return AutoClass
        # Alternatively, to autogenerate the classname as well as the class:
        # return type(self.__name__ + other.__name__, (self, other), {})

    def unregister(self):
        # classregistry.unregister(self)
        print "Would unregister class %s now." % self

class MyObject:
    __metaclass__ = MyType


class NoneSample(MyObject):
    pass

# Will print "NoneType None"
print type(NoneSample), repr(NoneSample)

class Example(MyObject):
    def __init__(self, value):
        self.value = value
    @make_hook
    def add(self, other):
        return self.__class__(self.value + other.value)

# Will unregister the class
Example.unregister()

inst = Example(10)
# Will fail with an AttributeError
#inst.unregister()

print inst + inst
class Sibling(MyObject):
    pass

ExampleSibling = Example + Sibling
# ExampleSibling is now a subclass of both Example and Sibling (with no
# content of its own) although it will believe it's called 'AutoClass'
print ExampleSibling
print ExampleSibling.__mro__
```
